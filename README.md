# ğŸ›ï¸ ShopSmart AI â€” Intelligent Data Platform on Azure

End-to-end **enterprise-grade Data Engineering project** built on Azure implementing a cloud-native **Medallion Architecture (Bronze â†’ Silver â†’ Gold)**.

This platform simulates a real-world e-commerce ecosystem with:

- âœ… Batch ingestion + transformations  
- âœ… Real-time streaming via Azure Event Hubs  
- âœ… PII masking + quarantine-based data quality framework  
- âœ… Star Schema modeling in Gold layer  
- âœ… ML use cases: RFM segmentation + payment anomaly detection  
- âœ… CI/CD with GitHub Actions â†’ Databricks deployment  

---

# ğŸ—ï¸ Architecture

| Layer | Technology |
|-------|------------|
| Storage | Azure Data Lake Storage Gen2 (ADLS) |
| Compute | Azure Databricks (PySpark + Spark SQL + Delta Lake) |
| Orchestration | Azure Data Factory (ADF) |
| Streaming | Azure Event Hubs |
| Secrets | Azure Key Vault + Databricks Secret Scope |
| Monitoring | Azure Monitor + Log Analytics |
| Infrastructure | Terraform (IaC) |
| CI/CD | GitHub Actions |

---

# ğŸ“Š Data Sources (6 + Streaming)

Synthetic enterprise e-commerce dataset simulating real production systems:

1. **Orders** (CSV â€” PostgreSQL export/CDC simulation)
2. **Order Items** (CSV)
3. **Customers** (Nested JSON â€” REST API simulation)
4. **Products** (Nested JSON â€” MongoDB simulation)
5. **Inventory** (CSV â€” daily snapshot)
6. **Payments** (JSON â€” payment gateway API simulation)
7. **Clickstream Events** (Real-time via Azure Event Hub)

---

# ğŸ¥‰ Bronze Layer (Raw Zone)

- Stores raw source data **as-is**
- Immutable ingestion
- Includes **quarantine area** for rejected records
- Stored in Delta format

---

# ğŸ¥ˆ Silver Layer (Cleaned & Validated)

### Data Engineering Features Implemented

- Type casting & schema enforcement  
- Standardization (trim, lower/upper case normalization)  
- Nested JSON flattening  
- Business logic transformations  
- Data quality validation rules  
- Quarantine pattern for invalid records  

### ğŸ” PII Governance

- `email` â†’ SHA-256 hash (`email_hash`)
- `phone` â†’ masked
- Null emails flagged for review

---

## Silver Tables Created

| Table | Records | Notes |
|-------|---------|-------|
| silver/orders | 1,948 | 52 quarantined (NULL order_status) |
| silver/order_items | 4,904 | Cleaned |
| silver/customers | 500 | PII masked; 53 null emails flagged |
| silver/products | 50 | Nested attributes flattened |
| silver/inventory | 150 | 4 negative stock corrected |
| silver/payments | 2,000 | Fraud signals engineered |
| silver/clickstream | 3,000 | Cleaned |
| silver/sessions | 3,000 | Session aggregates |
| silver/streaming_clickstream | Streaming | Event Hub ingestion |

---

# ğŸ¥‡ Gold Layer (Business-Ready Analytics)

Implements **Star Schema Modeling**

## Dimension Tables

- `gold/dim_date` (2024â€“2026)
- `gold/dim_customer` (SCD2-ready, surrogate keys)
- `gold/dim_product`

## Fact Tables

- `gold/fact_sales` (grain = 1 order line item)
- `gold/agg_daily_sales`

---
# ğŸ¤– Machine Learning / Advanced Analytics

## 1ï¸âƒ£ Customer Segmentation â€” RFM Model

Built using:

- Recency
- Frequency
- Monetary value

Quintile scoring (1â€“5) applied.

### Segment Distribution

- Champions â†’ 87
- Loyal Customers â†’ 132
- Potential Loyalists â†’ 150
- At Risk â†’ 67
- Hibernating â†’ 52

Output Table: `gold/ml_customer_rfm`

---

## 2ï¸âƒ£ Payment Anomaly Detection

Hybrid approach:

- Z-score anomaly detection (per payment method)
- Rule-based fraud indicators:
  - Off-hours transactions
  - High transaction amount
  - High risk score
  - International payments

### Example Output

- Statistical anomalies: 77
- CRITICAL risk: 106
- HIGH risk: 325

Output Table: `gold/ml_anomaly_detection`

---

# âš¡ Real-Time Streaming (Azure Event Hub)

### Flow

1. Python producer sends clickstream JSON events
2. Event Hub ingests events
3. Databricks streaming notebook consumes events
4. Data written to:
   - `bronze/streaming_clickstream`
   - `silver/streaming_clickstream`

> Demonstrates near real-time ingestion architecture

---

# ğŸ“ˆ Monitoring & Observability

Log Analytics Workspace: `log-shopsmart-dev`

Enabled diagnostics:

- ADLS transaction metrics
- ADF PipelineRuns
- ADF ActivityRuns
- TriggerRuns

---

# ğŸš€ CI/CD Pipeline

GitHub Actions automatically:

- Deploys notebooks to Databricks
- Maintains workspace sync
- Supports production-ready workflow

---
# ğŸ”® Future Enhancements

- Native Spark Structured Streaming connector (single-user cluster)
- Demand forecasting ML model
- Power BI dashboard connected to Gold layer
- Microsoft Purview for data lineage
- Advanced fraud detection using ML classifiers

---

# ğŸ¯ Key Takeaways

This project demonstrates:

- Enterprise Data Engineering best practices  
- Cloud-native architecture on Azure  
- Data quality + governance  
- Streaming + batch integration  
- Dimensional modeling  
- ML integration inside data platform  
- CI/CD automation  

---

# ğŸ‘¨â€ğŸ’» Author

**Bishmay Kumar**  
Data Engineering Enthusiast | Azure | Databricks | ML Integration  
